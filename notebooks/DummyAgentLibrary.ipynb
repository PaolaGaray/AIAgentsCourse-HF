{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dca3c189-4136-4e07-8ff7-3fa2981efb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantum physics is a branch of physics that deals with the behavior of matter and energy at the smallest scales, such as atoms and subatomic particles. It is a fundamental theory that describes the behavior of these particles and the forces that act upon them.\n",
      "In simple terms, quantum physics is the study of the tiny things that make up our world, like atoms and particles that are too small to see. It's like trying to understand how a tiny machine works, but instead of gears and levers, it\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "# API test\n",
    "output_0 = client.text_generation(\n",
    "    \"Explain quantum physics in simple terms.\", \n",
    "    max_new_tokens=100\n",
    ")\n",
    "\n",
    "print(output_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e65681a-6003-4520-b98c-c00d898780cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris. It is located in the north-central part of the country, along the Seine River. Paris is known for its stunning architecture, art museums, fashion, and romantic atmosphere. It is one of the most visited cities in the world, attracting millions of tourists each year.\n",
      "Paris is home to many famous landmarks, including the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and the Arc de Triomphe. The city is also known for its beautiful parks and gardens\n"
     ]
    }
   ],
   "source": [
    "# If we just do decoding, **the model will only stop when it predicts an EOS token**, \n",
    "# and this does not happen here because this is a conversational (chat) model \n",
    "# and we didn't apply the chat template it expects.\n",
    "\n",
    "output_1 = client.text_generation(\n",
    "    \"The capital of france is\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "print(output_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d4ef4d2-05b8-41c7-b376-384cec40a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# If we now add the special tokens related to Llama3.2 model, the behaviour changes and is now the expected one.\n",
    "prompt=\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "The capital of france is<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "output_2 = client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "print(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0132df5c-92f5-4044-bb94-d89b5ff7530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris!\n"
     ]
    }
   ],
   "source": [
    "# Using the \"chat\" method is a much more convenient and reliable way to apply chat templates:\n",
    "output = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"The capital of france is\"},\n",
    "    ],\n",
    "    stream=False,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "print(output.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3531a-a813-48e1-a5c0-584a50d72d51",
   "metadata": {},
   "source": [
    "# Dummy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7a9ee-06cc-4154-8ebb-ed93664ed1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
